# Introduction

Welcome to this repository where I share some of the most influential papers in the field of machine learning. This repository includes seminal works on various aspects of these topicss. Each paper listed has contributed significantly to advancing our understanding and capabilities in machine learning. Feel free to explore these papers to deepen your knowledge and stay updated with the latest advancements in this exciting field.

### Optimization Problem with Gradient Descent

* [Visualizing the Loss Landscape of Neural Nets](https://arxiv.org/abs/1712.09913)
* [On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima](https://arxiv.org/abs/1609.04836)
* [Large Batch Optimization for Deep Learning: Training BERT in 76 minutes](https://arxiv.org/abs/1904.00962)
* [Extremely Large Minibatch SGD: Training ResNet-50 on ImageNet in 15 Minutes](https://arxiv.org/abs/1711.04325)
* [Stochastic Weight Averaging in Parallel: Large-Batch Training that Generalizes Well](https://arxiv.org/abs/2001.02312)
* [Large Batch Training of Convolutional Networks](https://arxiv.org/abs/1708.03888)
* [Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://arxiv.org/abs/1706.02677)

### Adaptive Learning Rate

* [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)
* [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
* [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
* [On the Variance of the Adaptive Learning Rate and Beyond](https://arxiv.org/abs/1908.03265)

### Normalization

* [How Does Batch Normalization Help Optimization?](https://arxiv.org/abs/1805.11604)
* [Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models](https://arxiv.org/abs/1702.03275)
* [Layer Normalization](https://arxiv.org/abs/1607.06450)
* [Instance Normalization: The Missing Ingredient for Fast Stylization](https://arxiv.org/abs/1607.08022)
* [Group Normalization](https://arxiv.org/abs/1803.08494)
* [Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks](https://arxiv.org/abs/1602.07868)
* [Spectral Norm Regularization for Improving the Generalizability of Deep Learning](https://arxiv.org/abs/1705.10941)

